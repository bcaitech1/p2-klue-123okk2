# KLUE

### 데이터 전처리

1. Data Augmentation

 데이터 라벨의 불균형이 심했다. 이를 방지하기 위해 데이터 증강 기법을 사용했다.

 사용 기법은 총 네 가지로, 유사어 교체, 랜덤 단어 삭제, 랜덤 단어 추가, 단어 배열 변경 기법을 사용했다. 직접 구현하지는 않고, 기존에 만들어진 코드를 빌려왔으며, 카이스트에서 만든 WordNet을 기반으로 작업을 수행했다.
 
 라벨의 수에 따라 각자 다른 증가량을 두었다. (예를 들어 1000개 미만은 세 배로, 500개 미만은 6배로, 100개 미만은 30배로 등) 그리고 이 x배의 x를 서로 다르게 두어, 증강 데이터를 버전 1~4로 나누었다. 그리고 같은 코드로 각 증강 데이터를 검증했고, 버전 1이 가장 좋은 성능일 냈기에 계속 사용했다.

2. Additional Label

 토론 게시판에서 각 엔티티의 앞에 <E1>, <E2> 라벨을 붙이신 분의 코드를 보았다. 좋은 아이디어라고 판단해서 이를 따라했고, 성능이 1% 이상 향상됐다.


3. Incorrect Class 수정

 Slack에서 잘못된 분류가 있다는 공지를 확인했다. 잘못 분류된 문장들의 클래스와, 이를 토대로 증강된 문장들의 클래스를 다시 바로잡았다.


 ### 모델

 사실 이번 컴피티션에서는 직접 모델을 구성하거나 찾아서 빌려왔다기 보다, 다른 분들의 의견을 토대로 좋아보이는 모델들을 빌려와 진행했다.

 1. 뭐? 나도 70%를 찍을 수 있다고?

 베이스라인 코드를 기반으로 여러 하이퍼 파라미터를 변경하였으나, 대부분 60% 중반을 넘어서지 못했다. 그런데 때마침 위의 제목의 토론 글이 올라왔고, 캠퍼분께서 자신의 코드를 공유해주셨다. 그래서 빌려 사용했다.

 아무런 변경 없이 사용했을 때, 68%로 베이스라인 코드보다 좋은 성눙을 보여주었다. 그리고 Augmentation_v1 데이터를 사용했을 때 70%의 성능을 보여주었다.

 그래서 해당 코드가 완성본이라고 믿고 여러 하이퍼 파라미터를 변경해가며 실험을 진행했다. 그 결과 72% 정도 까지는 성능을 올릴 수 있었다.


2. 뭐? 나도 80%를 찍을 수 있다고?

 하지만 아무리 노력해도 72%를 넘어서는 성능을 보이지 못했다. 때마침 위의 캠퍼분께서는 이번에는 베이스라인 코드를 기반으로 80%의 성능을 보이신 코드를 선보이셨다. 그래서 마찬가지로 빌려 사용했다.

 하이퍼 파라미터 변경 없이 사용했을 때는 68%, 하이퍼 파라미터를 약간 변경하여 사용하니 69%의 성능이 나왔다. 그래서 증강한 데이터 (버전1)을 사용해볼 계획과, 라벨을 붙인 증강 데이터 (버전1)을 사용해 학습을 진행할 계획을 세웠다.

 하지만 때마침 함께 서버를 이용하시는 분께서 95G를 홀로 사용하신 덕에 서버가 터졌고, 이로 인해 실험이 미루어졌다. 그리고 다음 날 8시 50분에 학습을 완료해서 제출을 하려고 했으나, 이번에는 제출하는 서버가 터졌고, 덕분에 마지막 날 제출 횟수를 사용해야만 했다. 그리고 5번의 제출을 놓친 탓에 제출 횟수가 모자라 더 많은 실험을 진행하지는 못했다.

 ### 검증

1. Hard Vote

 1) 코드를 사용했을 때의 모델들 중 70% 이상의 성능을 보인 모델들의 결과를 종합해 Hard Vote를 사용했다. 만약 동점이 나올 경우 상위 두 개의 모델이 선택한 결과를 선택했다. 그 결과 성능이 73%대까지 올랐다.
 
 하지만 2) 코드를 사용한 모델들을 사용한 Hard Vote는 그렇게 좋은 성능을 보이지 못했다. 하루를 날린 탓에 시간이 모자라 많은 학습을 진행하지 못했고, 이로 인해 학습량이 적은 모델들이 하나의 모델의 성능에 미치지 못했다. 그래서 Vote 결과도 오히려 월등한 성능의 모델 하나만을 사용하는 것에 미치지 못했다.
